---
title: "Unsupervised Learning Mini Project"
author: "Shilpa Nath"
date: "10/29/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
read.csv("https://bioboot.github.io/bimm143_S18/class-material/WisconsinCancer.csv")
wisc.df <- read.csv("https://bioboot.github.io/bimm143_S18/class-material/WisconsinCancer.csv")
```
Note that the 'id' and 'diagnosis' columns will not be used for most of the following steps 

We have 'r nrow(wisc.df)' samples in this dataset
How many benign (not cancerous) and and malignant (cancerous) samples do we have in the dataset

```{r}
nrow(wisc.df)
table(wisc.df$diagnosis)
```

```{r}
# Convert the features of the data: wisc.data
wisc.data <- as.matrix(wisc.df[,3:32])

# Set the row names of wisc.data
row.names(wisc.data) <- wisc.df$id

head(wisc.data)
```

Store the diagnosis for reference in the furute as a seperate vector 
```{r}
diagnosis <- wisc.df$diagnosis
```

## Questions: 
Q1. How many observations are in this dataset?
```{r}
nrow(wisc.df)
```
Q2. How many of the observations have a malignant diagnosis?
```{r}
table(wisc.df$diagnosis)
```
Q3. How many variables/features in the data are suffixed with _mean?
```{r}
#shows alll the columns
colnames(wisc.df)

#finding the columns that are suffixed with _mean 
grep("_mean", colnames(wisc.df), value=TRUE)

#how many columns are suffixed with _mean
length(grep("_mean", colnames(wisc.df)))
```

```{r}
# Check column means
round(colMeans(wisc.data), 3)
```

```{r}
# Check column standard deviation 
round(apply(wisc.data, 2, sd), 3)
```

Since these values are very differnt the prcomp() value needs to be scaled, 'scale = TRUE' when PCA is run 
```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```

```{r}
plot(wisc.pr)
```


Lets make a plot of PC1 vs PC2
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2])
```

Color by diagnosis (malignant/benign)
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis, )
```

## Questions 
Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
**44.27%**
```{r}
x <- summary(wisc.pr)
x$importance[,"PC1"]
```

Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
**PC1 to PC3**
```{r}
which(x$importance[3,] > 0.7) [1]
```

Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
**PC1 to PC7**
```{r}
which(x$importance[3,] > 0.9) [1]
```

```{r}
# Scale the wisc.data data: data.scaled
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled, method = "euclidean")
wisc.hclust <- hclust(data.dist, method = "complete")
```

```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
```

```{r}
table(wisc.hclust.clusters, diagnosis)
```

```{r}
wisc.km <- kmeans(wisc.data, centers= 2, nstart= 20)
table(wisc.km$cluster, diagnosis)
```

## hierarchical Clustering 

```{r}
wisc.pr.hclust <-hclust(dist(wisc.pr$x[,1:7]), method="ward.D2")
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
#want to see the groups but with the diagnosis in each group
table(grps, diagnosis)

plot(wisc.pr$x[,1:2], col=grps)

plot(wisc.pr$x[,1:2], col=diagnosis)
```

## Section 7: Prediction 

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], labels=c(1,2), col="white")
```



















